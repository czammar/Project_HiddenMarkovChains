\documentclass[xcolor=dvipsnames, compress]{beamer}
%\usetheme{Madrid} % My favorite!
%\usetheme{Boadilla} % Pretty neat, soft color.
%\usetheme{Warsaw}
%\usecolortheme{dove} 
\usetheme[secheader]{Boadilla}
% \useoutertheme[subsection=false]{smoothbars}
% \useinnertheme{rectangles}
% \usetheme{Marburg}
   \usecolortheme[RGB={139,10,80}]{structure}
%  \usecolortheme[RGB={25,25,112}]{structure}
%\usecolortheme[RGB={255,127,36}]{structure}
% \usetheme{CambridgeUS}
%\usetheme{PaloAlto}
% \usefonttheme{professionalfonts}
% \usepackage{listings}

\usetheme{Boadilla}

% \usetheme{Warsaw}
%\usetheme{Darmstadt} %OK!
%  \usetheme{Frankfurt} %OK!
% \usetheme{Goettingen}
% \usetheme{Dresden}
%\usetheme{JuanLesPins} %OK!!
%\usetheme{Marburg}
%  \usetheme{Montpellier}
% \usetheme{Rochester} %sobrio
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Luebeck}

%\usetheme{Hannover}
%\usecolortheme{wolverine}

%\usecolortheme{albatross}
%\usecolortheme{seahorse}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove} %<- este con orchid
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{whale}

%\usetheme{Bergen} % This template has nagivation on the left
%\usetheme{Frankfurt} % Similar to the default 
%with an extra region at the top.
%\usecolortheme{seahorse} % Simple and clean template
%\usetheme{Darmstadt} % not so good
% Uncomment the following line if you want %
% page numbers and using Warsaw theme%
% \setbeamertemplate{footline}[page number]
%\setbeamercovered{transparent}
%\setbeamercovered{invisible}
% To remove the navigation symbols from 
% the bottom of slides%
%\setbeamertemplate{navigation symbols}{} 
%
\usepackage{graphicx}
\usepackage{amssymb,amsmath,amscd}
\usepackage{latexsym,xspace}
\usepackage[utf8]{inputenc}
\usepackage{epsfig}
%\usepackage{fancyhdr}
%\usepackage[spanish]{babel}
\usepackage[all]{xy}
\usepackage{enumerate}
\usepackage{eucal}
%\usepackage[usenames]{color}

\usepackage{mathtools} % flechas con nombres arriba o abajo

%#########################
\newcommand{\tx}{\ensuremath{\tau(X)}}
\newcommand{\txx}{\ensuremath{\tau_{X}}}
\newcommand{\Q}{\ensuremath{\mathbb{Q}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\A}{\ensuremath{\forall}}
\newcommand{\E}{\ensuremath{\exists}}
\newcommand{\iso}{\ensuremath{\cong}}
\newcommand{\union}{\ensuremath{\cup}}
%\newcommand{\morinyec}{\ensuremath{\precapprox}}
%\newenvironment{prueba}{\vspace{-3mm}\noindent\textbf{Demostraci\'on}\\}{\noindent$\blacksquare$\\}
\newcommand{\nin}{\ensuremath{\notin}}
\renewcommand{\emptyset}{\varnothing}

%\newcommand{\niso}{\ensuremath{\not \cong}}
\newtheorem{teor}{Teorema}[section]
\newtheorem{defi}{Definition}[section]
\newtheorem{ejemplo}{Examples}[section]
\newtheorem{obs}{Remark}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{ntc}{Notation}[section]
\newtheorem{lema}{Lemma}[section]
\newtheorem{prob}{Problem}
\newtheorem{comen}{Comment}

%\usepackage{bm}         % For typesetting bold math (not \mathbold)
%\logo{\includegraphics[height=0.6cm]{yourlogo.eps}}
%
\title[Hidden Markov Chains]{Hidden Markov Chains}
\author{Marco Julio, Nicolás, Sebastián and César}
\institute[ITAM]
%\date{November 7, 2019}
% \today will show current date. 
% Alternatively, you can specify a date.
%


\begin{document}
%
\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\frametitle{Index}
 \tableofcontents%[sections]
\end{frame}


%\begin{frame}
%\section{Prediction}
%\frametitle{Prediction}
%
%\begin{block}{Prediction}
%	 \textbf{Given:} observations up to time s (i.e. $y_{1:s}$ known),\\
%	 \textbf{Problem:} compute $p(x_t | y_{1:s})$ distribution of $X_t$, for $t > s$.
%\end{block}
%
%\end{frame}

\begin{frame}
\section{Smoothing}
\frametitle{Smoothing}

\textbf{General problem of smoothing:}\\
\textbf{Given:} observations up to time s (i.e. $y_{1:s}$ known),\\
\textbf{Problem:} compute $p(x_t | y_{1:s})$ distribution of $X_t$, for $t < s$.
\vspace{0.5cm}

A particular case is when we know all history of observations:

\begin{block}{Smoothing with all history of observations}
	\textbf{Given:} observations up to time T (i.e. $y_{1:T}$ known),\\
	\textbf{Problem:} compute $p(x_t | y_{1:T})$ distribution of $X_t$, for $t < T$.
\end{block}

This case can be solved using a recursive algorithm \textbf{Forward-backward Smoothing}.

\end{frame}


\begin{frame}
\frametitle{Forward-backward Smoothing I}

\textbf{Ideas:}

\begin{itemize}
\item  $p(x_t |y_{1:T})$ can be split as:
$$p(x_t |y_{1:T}) = \frac{p(x_t , y_{1:t} ) \cdot p(y_{t+1:T} |x_t )}
	{p(y_{1:T})}$$
	
\item $p(y_{1:T})$ is a normalization constant (calculation explained in next section).
	
\item Algorithm 1 Forward $\alpha$-recursion can estimate $\alpha_t(x_t)=p(x_t , y_{1:t} )$.

\item We can approach HHM structure to generate a recursion rule for $$\beta_t(x_t):=p(y_{t+1:T} |x_t )$$

\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Forward-backward Smoothing II}
\begin{eqnarray*}
\textcolor{red}{p(y_{t+1:T} |x_{t-1} )} & = & \sum_{x_t \in \mathcal{X}} p(y_{t+1:T},x_t |x_{t-1} )\\
                       & = & \sum_{x_t \in \mathcal{X}} p(y_{t}|y_{t+1:T},x_t,x_{t-1} |x_{t-1} ) p(y_{t+1:T},x_t |x_{t-1} ) \\
     & = & \sum_{x_t \in \mathcal{X}} p(y_{t}|x_{t-1},x_t) p(y_{t+1:T}|x_t)\\
     & = & \sum_{x_t \in \mathcal{X}} p(y_{t}|x_t) \textcolor{red}{p(y_{t+1:T}|x_t)} p(y_{t}|x_{t-1})\\   
\end{eqnarray*}
We have a backward recursion for $t=T, \ldots, 2$

$$ \textcolor{red}{\beta_{t-1}(x_{t-1})} = \sum_{x_t \in \mathcal{X}} p(y_{t}|x_t)  p(x_{t}|x_{t-1}) \textcolor{red}{\beta_t(x_t)}, \mbox{ } \beta_T(x_T)=1 $$

\end{frame}

\begin{frame}
\frametitle{Forward-backward Smoothing III}

If $\mathcal{X}=\{1,\ldots, K\}$:
\begin{figure}
	\includegraphics[scale=0.45]{images/backward_beta_recursion.jpg}
	\caption{Backward $\beta$-recursion Algorithm}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Forward-backward Smoothing III}
\textbf{Backward and Forward Algorithm for smoothing:}

\begin{itemize}
	\item Algorithm 1 Forward $\alpha$-recursion to get $\alpha_t(x_t)=p(x_t , y_{1:t})$.
	\item Algorithm 2 Backward $\beta$-recursion to get $\beta_t(x_t)=p(y_{t+1:T} |x_t )$.
	\item Smoothing probability mass function is estimated as:
	
	$$ p(x_t | y_{1:T}) = \frac{p(x_t, y_{1:T})}{p(y_{1:T})}=\frac{\alpha_t(x_t) \beta_t(x_t)}{\sum_{x_t \in \mathcal{X}} \alpha_t(x_t) \beta_t(x_t)}$$

\end{itemize}
\vspace{0.5cm}
 \textbf{Notes:} 1) Algorithms 1 y 2 can be run independently, 2) Backward and Forward Algorithm is from order $\mathcal{O}(T\cdot|\mathcal{X}|^2)$

\end{frame}


\begin{frame}
\section{Likelihood}
\frametitle{Likelihood}

\textbf{Given:} all observations (i.e. $y_{1:T}$ known),\\
\textbf{Problem:} compute $p(y_{1:T})$ likelihood function of observations.

\vspace{0.5cm}

\textbf{Ideas:}

\begin{itemize}
	\item Notice $$p(y_{1:T} ) = \sum_{x_t \in \mathcal{X}} p(x_t , y_{1:t} ) \cdot p(y_{t+1:T} |x_t )$$
	\item This implies $$p(y_{1:T} ) = \sum_{x_t \in \mathcal{X}} \alpha_t(x_t) \beta_t(x_t) $$
	
	\item $p(y_{1:T} )$ can be estimated using algorithm 1 Forward $\alpha$-recursion and algorithm 2 Backward $\beta$-recursion.
	
\end{itemize}

\end{frame}

\begin{frame}
\section{Most likely state path/Decoding}
\frametitle{Most likely state path/Decoding}

\textbf{Given:} history of observations (i.e. $y_{1:T}$ known),\\
\textbf{Problem:} Find the most likely state history $x_{0:T}$.

\vspace{0.5cm}

For fixed $y_{1:T}$, solve MAP problem with \textbf{conditional distribution}:
\begin{equation*}
\hat{x}_0 = argmax_{x_{0:T}} \hspace{0.2cm} p(x_{0:T}| y_{1:T}) 
\end{equation*}
Or equivalently with \textbf{joint distribution}:
\begin{equation*}
\hat{x}_0 = argmax_{x_{0:T}} \hspace{0.2cm} p(x_{0:T}, y_{1:T})
\end{equation*}

\textbf{Note:} unfeasible if number of different state paths $|\mathcal{X}|^{T+1}$ is large from optimization point of view!!.

\end{frame}

\begin{frame}
\frametitle{Most likely state path - Viterbi algorithm}

However, we can use \textbf{Viterbi algorithm} to do MAP estimation.

\textbf{Ideas:}

\begin{itemize}
	\item Explote structure of HMM do estimations based on backward-forward or forward-backward recursions.
	\item Compute \textcolor{red}{messages} from time $t$  to $t-1$ ($m_{t-1}(x_{t-1}) \leftarrow m_{t}(x_{t})$)
	\item Use \textcolor{red}{messages} to estimate feasible points $t-1$  to $t$ ($\hat{x}_{t-1} \rightarrow \hat{x}_{t}$)	
\end{itemize}

\begin{figure}
	\includegraphics[scale=0.4]{images/viterbi1.jpg}
	\caption{Scheme of Vitterbi algorithm recursions}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{What do you mean by \textcolor{red}{messages $m_t(x_t)$}? Part I}

Factorizing $p(x_{0:T},y_{1:T})$:
$$p(x_{0:T},y_{1:T}) = p(x_0)\prod_{t=1}^T p(x_{t}|x_{t-1}) p(y_{t}|x_{t})$$
We can split our optimization problem in different optimization problems:
$$\Rightarrow \max_{ \textcolor{red}{ x_0:x_T} } p(x_{0:T},y_{1:T}) =$$ 
$$ \max_{ \textcolor{red}{ x_0:x_{T-1}} } \left\{ \left\{ p(x_0)  \prod_{t=1}^{\textcolor{red}{T-1}} p(x_{t}|x_{t-1}) p(y_{t}|x_{t}) \right\} \max_{ \textcolor{red}{ x_{T}} } p(x_{\textcolor{red}{T}}|x_{\textcolor{red}{T-1}}) p(y_{\textcolor{red}{T}}|x_{\textcolor{red}{T}})  \right \}$$
$$=\max_{ \textcolor{red}{ x_0:x_{T-1}} } \left\{ \left\{ p(x_0)  \prod_{t=1}^{\textcolor{red}{T-1}} p(x_{t}|x_{t-1}) p(y_{t}|x_{t}) \right\} m_{\textcolor{red}{T-1}}(x_{\textcolor{red}{T-1}})  \right \}$$

\end{frame}

\begin{frame}
\frametitle{What do you mean by \textcolor{red}{messages $m_t(x_t)$}? Part II}

Continuing this process we can define a set of messages based on iterative optimization problems:
$$m_{t-1}(x_{t-1}) = \max_{  x_{t:T} }\left\{    \prod_{k=t}^{T} p(x_{k}|x_{k-1}) p(y_{k}|x_{k}) \right\} \mbox{ for } t=T-1, \ldots, 1$$
$$m_T(x_T)=1$$

\vspace{0.3cm}

This satisfies the following recursion:

$$ \textcolor{red}{m_{t-1}(x_{t-1})}  = \max_{  x_{t} } p(y_t | x_t) p(x_t | x_{t-1}) \textcolor{red}{m_t(x_t)}$$

\end{frame}

\begin{frame}
\frametitle{What do you mean by \textcolor{red}{messages $m_t(x_t)$}? Part III}
Definitions of messages is good for our problem because:
$$p(x_0) m_0(x_0) = \max_{x_{1:T}} p(x_{0:T}, y_{1:T})$$
$$\Rightarrow \hat{x_0} = arg \max_{x_0} \left(\max_{x_{1:T}} p(x_{0:T}, y_{1:T}) \right) = arg \max_{x_0} m_0(x_0) p(x_0) $$

And also

$$ \hat{x_t} = arg \max_{x_t} p( \textcolor{red}{ \hat{x}_{0:t-1}}, x_t, x_{t+1:T},y_{1:T} )$$
$$ = arg \max_{x_t} p(\textcolor{red}{\hat{x}_{t-1}}, x_t, x_{t+1:T},y_{1:T} )$$

$$ = arg \max_{x_t} \left(\textcolor{red}{m_t(x_{t})} p(y_t|x_t)  p(x_t | \hat{x}_{t-1})\right) $$

\end{frame}

\begin{frame}
\frametitle{Most likely state path - Viterbi algorithm}
\begin{figure}
	\includegraphics[scale=0.45]{images/viterbi2.jpg}
	\caption{Vitterbi algorithm}
\end{figure}

\textbf{Notes:} 1) Viterbi algorithm has order $\mathcal{O}(T |\mathcal{X}|^2)$, 2) In practice logarithms are computed to assure numerical stability.

\end{frame}



\begin{frame}
\section{Continuous-state Hidden Markov Models}
\frametitle{Continuous-state Hidden Markov Models}

In many problems often hidden parameters of interest are continuous. 

\begin{figure}
	\includegraphics[scale=0.45]{gps_cut.png}
	\caption{GPS object tracking; hidden parameters: position + velocity}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Continuous-state Hidden Markov Models}
\begin{itemize}	

	\item Ideas developed for discrete case can be generalized to aboard problems with hidden continuous parameters of interest.\vspace{0.5cm}
	\item We call these \textbf{Continuous-state Hidden Markov Models} (CS-HMM), also named as state-space models or dynamical systems.\vspace{0.5cm}
	\item Let's focus on a particular subset of CS-HMM: \textbf{linear Gaussian state-space model} (LGSSM).
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Linear Gaussian state-space model (LGSSM)}

\textbf{Hidden states:} $(X_0, \ldots, X_T)$ continuous r.v. taking values in $\R^{d_x}$

\textbf{Observations:} $(Y_1, \ldots, Y_T)$ continuous r.v. taking values in $\R^{d_y}$\vspace{0.5cm}

$(X_0, \ldots, X_T, Y_1, \ldots, Y_T)$ is LGSSM if has two components such as: 

\begin{itemize}
\item \textbf{state model:} $X_{t}$ is a linear transformation of $X_{t-1}$ plus a linear combination of Gaussian noise.\vspace{0.5cm}

\item \textbf{observation model:} $Y_{t}$ is a linear transformation of $X_{t}$ plus Gaussian noise.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Linear Gaussian state-space model (LGSSM)}
\begin{defi}[LGSSM - State model]

\begin{equation}
X_t = F_t X_{t-1} + G_t V_t \mbox{ for } t=1, \ldots, T \mbox{ State model }
\end{equation}

\end{defi}

\begin{itemize}
	\item $X_t \in  \R^{d_x}$ hidden state at time $t$,
	\item $F_t \in  \R^{d_x \times d_x}$ transition state matrix at time $t$,
	\item $G_t \in  \R^{d_x \times d_v}$ noise transfer matrix,
	\item $V_t \in  \R^{d_v}$ state noise matrix, $V_t \sim \mathcal{N}(0,Q_t)$.
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Linear Gaussian state-space model (LGSSM)}

\begin{defi}[Observation model]
	\begin{equation}
	Y_t = H_t X_{t} + W_t \mbox{ for } t=1, \ldots, T \hspace{1cm}  \mbox{ Observation model }
	\end{equation}
	
\end{defi}

\begin{itemize}
	\item $Y_t \in  \R^{d_y}$ observation at time $t$,
	\item $H_t \in  \R^{d_x \times d_x}$ observation matrix at time $t$,
	\item $W_t \in  \R^{d_v}$ observation noise, $W_t \sim \mathcal{N}(0,R_t)$.
\end{itemize}

\begin{defi}[Other conditions]
	\begin{itemize}
		\item $X_0\sim \mathcal{N}(\mu_0,\Sigma_0)$,
		\item $V_t \sim \mathcal{N}(0,Q_t), W_t \sim \mathcal{N}(0,R_t)$, for $t=1,\ldots T$,
		\item $X_0, V_1, \ldots V_T, W _1, \ldots W_T$  are independent.
	\end{itemize}
\end{defi}

\end{frame}

\begin{frame}
\frametitle{LGSSM and parametrization of joint pdf}

As in discrete case, joint pdf of hidden variables and observation can be described as:
\begin{equation}
p(X_{0:T}, Y_{1:T}) = \prod_{t=1}^T p(y_t|x_t) \cdot p(x_{t-1}|x_t)
\end{equation}

Using \textbf{LGSSM structure} and \textbf{properties of multivariate normal distributions} it can be shown that if $G_t Q_T G_T\in \R^{d_x \times d_x}$ has full rank then:

\begin{equation}
p(y_t|x_t) = \mathcal{N}(H_t x_{t}, R_t)
\end{equation}

%\begin{equation}
%p(x_t|x_{t-1}) = \mathcal{N}(x_t; H_t x_{t}, R_t)
%\end{equation}

\begin{equation}
p(x_t|x_{t-1}) = \mathcal{N}(F_t x_{t-1}, G_t Q_T G_T)
\end{equation}

\end{frame}




\begin{frame}
\frametitle{Inference in dynamic LGSSM}

Let's consider the following inference problem:

\textbf{P1:} Given \textbf{observations up to time} $t$ find $Y_1=y_1, \ldots, Y_t=y_t$, find joint pdf $p(x_t|y_{1:t})$.\vspace{0.5cm}

\textbf{P2:} Given \textbf{all observations} $Y_1=y_1, \ldots, Y_T=y_T$, find joint pdf $p(x_t|y_{1:T})$\vspace{0.5cm}

Both can be solve by \textbf{sequentially computation of means  and  covariance  matrices of conditionally distributions}: 1)  P1 is called \textbf{Kallman filter}, and in 2) P2 is named \textbf{Kallman smoother}.
\end{frame}

\begin{frame}
\frametitle{Inference LGSSM - Kallman filter}

\textbf{P1:} Determine $p(x_t|y_{1:t})$ of the hidden state $X_t$ given $t$ observations $y_{1:t}$. 

\begin{equation}
\mu_{t|t-1}:= E[X_t | Y_{1:t} = y_{1:t-1} ]
\end{equation}

\begin{equation}
\mu_{t|t}:= E[X_t | Y_{1:t} = y_{1:t} ]
\end{equation}

\begin{equation}
\Sigma_{t|t-1}:= E[(X_t -\mu_{t|t-1}) (X_t -\mu_{t|t-1})^T | Y_{1:t} = y_{1:t-1} ]
\end{equation}

\begin{equation}
\Sigma_{t|t}:= E[(X_t -\mu_{t|t}) (X_t -\mu_{t|t})^T | Y_{1:t} = y_{1:t} ]
\end{equation}

\end{frame}

\begin{frame}
\frametitle{Kallman filter ideas - Prediction}

Structure of LGSSM implies $p(x_t| y_{1:t-1})=\mathcal{N}( \mu_{t|t-1}, \Sigma_{t|t-1}  )$ and the existence of recursive rules: \vspace{0.5cm}

\textbf{Prediction} ($\mu_{t-1|t-1} \rightarrow \mu_{t|t-1} $) and ($\Sigma_{t-1|t-1} \rightarrow \Sigma_{t|t-1} $):
\begin{itemize}
	\item $\mu_{t|t-1} = F_t \mu_{t-1|t-1}$, 
	\item $\Sigma_{t|t-1} = F_t \Sigma_{t-1|t-1} F_t^T+ G_t Q_t G_t^T$
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Kallman filter ideas - Update/correction} 
Again, structure of LGSSM implies $p(x_t| y_{1:t})=\mathcal{N}( \mu_{t|t}, \Sigma_{t|t})$ and following recursion rule: \vspace{0.5cm}

\textbf{Update/correction} ($\mu_{t|t-1} \rightarrow \mu_{t|t} $) and ($\Sigma_{t|t-1} \rightarrow \Sigma_{t|t} $):
\begin{itemize}
	\item $\mu_{t|t} = \mu_{t|t-1} + K_{t} \nu_{t}$, 
	\item$\Sigma_{t|t-1} = (I-K_t H_t) \Sigma_{t-1|t-1}$
\end{itemize}

Where $\nu_t = y_t - \hat{y}_t$, $\hat{y}_t=E[Y_t|Y_{1:t-1}=y_{1:t-1}]=H_t\mu_{t|t-1}$ 

$K_t=\Sigma_{t|t-1}H^T S_t^{-1}$, $S_t=E[(Y_t - \hat{y}_t)(Y_t - \hat{y}_t)^T | Y_{1:t-1} = y_{1:t-1} ] = H_t\Sigma_{t|t-1}H_t^T +R_t$

$K_t$ is called \textbf{Kallman gain}
\end{frame}

\begin{frame}
\frametitle{Kallman filter ideas} 

\textbf{Recursive strategy of Kallman filter}

$p(x_t|y_{1:t})$ can be determined estimating parameters for $s\in \N$ of:
\begin{itemize}
\item $p(x_s| y_{1:s-1})=\mathcal{N}( \mu_{s|s-1}, \Sigma_{s|s-1})$
\item $p(x_s| y_{1:s})=\mathcal{N}( \mu_{s|s}, \Sigma_{s|s})$
\end{itemize}

as follows:

$$(\mu_0, \Sigma_0) \xrightarrow[]{\text{Predict.}} (\mu_{1|0}, \Sigma_{1|0}) \xrightarrow[]{\text{Update}} \ldots $$ 
$$\ldots \xrightarrow[]{\text{Predict.}} (\mu_{t-1|t-1}, \Sigma_{t-1|t-1})\xrightarrow[]{\text{Update}}$$ 
$$(\mu_{t|t-1}, \Sigma_{t|t-1}) \xrightarrow[]{\text{Predict.}} (\mu_{t|t}, \Sigma_{t|t}) \xrightarrow[]{\text{}} \ldots $$

\end{frame}

\begin{frame}
\frametitle{Inference LGSSM - Kallman Smoother}

 \textbf{P2:} Determine $p(x_t|y_{1:T})$ of the hidden state $X_t$ given all the observations $y_{1:T}$. 

\begin{equation}
\mu_{t|T}:= E[X_t | Y_{1:T} = y_{1:T} ]
\end{equation}

\begin{equation}
\Sigma_{t|T}:= E[(X_t -\mu_{t|T}) (X_t -\mu_{t|T})^T | Y_{1:T} = t_{1:T} ]
\end{equation}

\end{frame}


\begin{frame}
\frametitle{Kallman Smoother ideas}

Structure of LGSSM implies $p(x_t| y_{1:T})=\mathcal{N}( \mu_{t|T}, \Sigma_{t|T}  )$ and the existence of recursive rules: \vspace{0.5cm}

\textbf{Backward recursion}:
\begin{itemize}
	\item $\mu_{t|T} = \mu_{t|t} + J_t (\mu_{t+1|T} - \mu_{t+1|t})$, 
	\item $\Sigma_{t|T} = \Sigma_{t|t} + J_t (\Sigma_{t+1|T} - \Sigma_{t+1|t})J_t^T$
\end{itemize}
\vspace{0.5cm}
Where $J_t = \Sigma_{t|t} F_{t+1}^T \Sigma_{t+1|t}^{-1}$, is called \textbf{Backwards Kallman gain}.

\end{frame}

\begin{frame}

\textbf{Recursive strategy of Kallman Smoother}

$p(x_t|y_{1:T})$ can be determined estimating parameters as follows:

\begin{itemize}
	\item Compute $(\mu_{t|t}, \Sigma_{t|t})$ and $(\mu_{t+1|t}, \Sigma_{t+1|t})$ for $t,t+1 \leq T$ using Kallman filter.
	\item Use backward recursion until obtain $(\mu_{t|T}, \Sigma_{t|T})$.
\end{itemize}
\end{frame}

\begin{frame}
\section{An example for LGSSM}
\frametitle{A example for LGSSM}
Let's consider a toy example for a random walk given by:
$$X_t = X_{t-1} + V_t $$
$$Y_t = X_{t} + W_t $$

Where 

\begin{itemize}
	\item$X_{t}$: trigonometric function plus gaussian noise, for $t=1,\ldots, 50$.
	\item $X_0 = \mathcal{N}(0,1)$, $V_t \sim \mathcal{N}(0,Q)$, $W_t \sim \mathcal{N}(0,R)$, with $Q=0.02$ and $R=0.2$
\end{itemize}



\end{frame}


\begin{frame}
\frametitle{Filtering}
\begin{figure}
	\includegraphics[scale=0.7]{filtermean_obs.png}
	\caption{Observations and filtering mean and 99\% credible intervals over time.}
\end{figure}
\end{frame}

\begin{frame}
\section{An example for LGSSM}
\frametitle{Smoothing}
\begin{figure}
	\includegraphics[scale=0.7]{smoothmean_obs.png}
	\caption{Observations and smoothing mean and 99\% credible intervals over time}
\end{figure}
\end{frame}

%
%\begin{frame}[fragile] % Notice the [fragile] option %
%\frametitle{Verbatim}
%\begin{example}[Putting Verbatim]
%\begin{verbatim}
%\begin{frame}
%\frametitle{Outline}
%\begin{block}
%{Why Beamer?}
%Does anybody need an introduction to Beamer?
%I don't think so.
%\end{block}
% Extra carriage return causes problem with verbatim %
%\end{frame}\end{verbatim} 
%\end{example}
%\end{frame}
 
%\begin{frame}[fragile]  % notice the fragile option, since the body
			% contains a verbatim command
%Example of the \verb|\cite| command to give a reference is below:
%Example of citation using \cite{key1} follows on.
%\end{frame}
 
% \begin{frame}
% \section{Bibliografía}
% \frametitle{Referencias}
% \footnotesize{
% \begin{thebibliography}{99}
%  \bibitem[Morita, 2010]{key1} J. Nagata, K. Morita (1989)
%  \newblock Topics On General Topology.
%  \newblock \emph{Elsevier Science Publisher B.V.} 15(6), 203 -- 243.

% \bibitem[VanMill, 2010]{key1} J. Van Mill ; M. Husek (1992)
%  \newblock Recent Progress In General Topology.
%  \newblock \emph{Elsevier Publications} p. 375.

% \bibitem[MacLane, 2010]{key1} J. S. Mac Lane(1971)
%  \newblock Categories for the working mathematician,.
%  \newblock \emph{Springer} p. 375.

%  \bibitem[Ishii, 2010]{key1} Tadashi Ishii (1969)
%  \newblock On Tychonoff Functor and $w$-Compactness.
%  \newblock \emph{Topology Appl.} 11, 175 -- 187.

%  \bibitem[Ishii, 2010]{key1} T. Hoshina; K. Morita (1980)
%  \newblock On Regular Products Of Topological Spaces.
%  \newblock \emph{Topology Appl.} 11, 47 -- 57.
% \end{thebibliography}
% }
% \end{frame}


 
% \begin{frame}
% %\section{Bibliografía}
% \frametitle{Referencias}
% \footnotesize{
% \begin{thebibliography}{99}
%  \bibitem[Porter, 2010]{key1}J. R. Porter ; R. Grant Woods  (1987)
%  \newblock Extensions and Absolutes of Hausdorff Spaces.
%  \newblock \emph{Springer-Verlag} 856.


%  \bibitem[Simon, 2010]{key1} Petr Simon (1984)
%  \newblock Completely regular modification and products.
%  \newblock \emph{Commentationes Mathematicae Universitatis Carolinae} 25(1), 121--128.



%  \bibitem[Puppier, 2010]{key1} René Puppier (1969)
%  \newblock La Completion Universelle D'un Produit D'espaces Completement Reguliers .
%  \newblock \emph{Publ. Dept. Math, Lyon} 254, 342--351.



% \end{thebibliography}
% }
% \end{frame}
% 
% End of slides
\end{document} 